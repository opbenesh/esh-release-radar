{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b88147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import threading\n",
    "import logging\n",
    "import time\n",
    "import itertools\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from collections import Counter\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import os\n",
    "import spotify_utils as spu\n",
    "from operator import itemgetter\n",
    "from os.path import join as pj\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbfcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "REFRESH_CACHE = False\n",
    "seen_playlist_id = \"5al4jEBoq01LPmFDuGDnq4\"      # Automated: Reviewed Items\n",
    "played_playlist_id = \"7EHT9D4ygqDlyGfqcFvkUv\"    # 5 Esh Played\n",
    "inbox_playlist_id = \"1xsuqA0HU4bSosdaPyVlWG\"     # 1 Esh Review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_CACHE:\n",
    "    sp = spu.spotify_connect()\n",
    "    seen_tracks = spu.get_playlist_tracks(sp,seen_playlist_id,audio_features=True)\n",
    "    played_tracks = spu.get_playlist_tracks(sp,played_playlist_id)\n",
    "    review_tracks = spu.get_playlist_tracks(sp,inbox_playlist_id)\n",
    "    seen_tracks.to_csv('seen_tracks.csv',index=False)\n",
    "    played_tracks.to_csv('played_tracks.csv',index=False)\n",
    "    played_tracks.to_csv('played_tracks.csv',index=False)\n",
    "    review_tracks.to_csv('review_tracks.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9376cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tracks = pd.read_csv('seen_tracks.csv')\n",
    "played_tracks = pd.read_csv('played_tracks.csv')[\"id\"]\n",
    "seen_tracks = seen_tracks.merge(played_tracks,how='left',on=[\"id\"],indicator=\"played\")\n",
    "seen_tracks[\"played\"] = seen_tracks[\"played\"].apply(lambda i: 1 if i==\"both\" else 0)\n",
    "seen_tracks = seen_tracks.dropna()\n",
    "X = seen_tracks[spu.audio_features_to_use]\n",
    "y = seen_tracks[\"played\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6f00cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8640\n",
       "1     272\n",
       "Name: played, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c519de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic model evaluator\n",
    "def evaluate_model(name,model,splitter,transformer,X,y):\n",
    "    X,y = transformer(X,y)\n",
    "    X_train, X_test, y_train, y_test = splitter(X,y,random_state=0)\n",
    "    training_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_end = time.time()\n",
    "    training_duration = training_end - training_start\n",
    "    training_score = \"{:.2f}\".format(model.score(X_train,y_train))\n",
    "    test_score = \"{:.2f}\".format(model.score(X_test,y_test))\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    tp = y_test_pred\n",
    "    CM = confusion_matrix(y_test,y_test_pred)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return (name,training_duration,FP,FN,TP,TN)\n",
    "\n",
    "def stratified_split(X,y,random_state):\n",
    "    return train_test_split(X,y,stratify=y,test_size=0.25,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ef43f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy,RandSplit,Identity,0.0020017623901367188,0,73,0,2155\n",
      "KNN,RandSplit,Identity,0.01600503921508789,0,73,0,2155\n",
      "Logistic Regression,RandSplit,Identity,0.15770816802978516,0,73,0,2155\n",
      "Decision tree,RandSplit,Identity,0.13010907173156738,89,71,2,2066\n",
      "Random forests,RandSplit,Identity,2.6348989009857178,1,73,0,2154\n",
      "Dummy,StratSplit,Identity,0.0010750293731689453,0,68,0,2160\n",
      "KNN,StratSplit,Identity,0.01700282096862793,0,68,0,2160\n",
      "Logistic Regression,StratSplit,Identity,0.21829676628112793,0,68,0,2160\n",
      "Decision tree,StratSplit,Identity,0.12053179740905762,76,64,4,2084\n",
      "Random forests,StratSplit,Identity,3.6953976154327393,2,68,0,2158\n",
      "Dummy,RandSplit,Over-sample,0.0010006427764892578,0,2196,0,2124\n",
      "KNN,RandSplit,Over-sample,0.03705453872680664,268,0,2196,1856\n",
      "Logistic Regression,RandSplit,Over-sample,0.29563236236572266,960,545,1651,1164\n",
      "Decision tree,RandSplit,Over-sample,0.1710829734802246,87,0,2196,2037\n",
      "Random forests,RandSplit,Over-sample,4.5792076587677,3,0,2196,2121\n",
      "Dummy,StratSplit,Over-sample,0.0,0,2160,0,2160\n",
      "KNN,StratSplit,Over-sample,0.035085201263427734,253,0,2160,1907\n",
      "Logistic Regression,StratSplit,Over-sample,0.31275296211242676,1029,508,1652,1131\n",
      "Decision tree,StratSplit,Over-sample,0.2802622318267822,103,0,2160,2057\n",
      "Random forests,StratSplit,Over-sample,5.796451091766357,3,0,2160,2157\n"
     ]
    }
   ],
   "source": [
    "models = [(\"Dummy\",DummyClassifier(random_state=0,strategy=\"constant\",constant=0)),\n",
    "          (\"KNN\",KNeighborsClassifier()),\n",
    "          (\"Logistic Regression\",LogisticRegression()),\n",
    "          (\"Decision tree\",DecisionTreeClassifier(random_state=0)),\n",
    "          (\"Random forests\",RandomForestClassifier(random_state=0))\n",
    "         ]\n",
    "spliiters = [(\"RandSplit\",train_test_split),\n",
    "             (\"StratSplit\",stratified_split)\n",
    "            ]\n",
    "transformers = [(\"Identity\",lambda X,y: (X,y)),\n",
    "                (\"Over-sample\",RandomOverSampler(random_state=0).fit_resample)\n",
    "               ]\n",
    "results = []\n",
    "for transformer_name,transformer in transformers:\n",
    "    for splitter_name,splitter in spliiters:\n",
    "        for model_name,model in models:\n",
    "            results.append(evaluate_model(f'{model_name},{splitter_name},{transformer_name}',model,splitter,transformer,X,y))\n",
    "print('\\n'.join([','.join(map(str,res)) for res in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating different models\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    # {'classifier': [KNeighborsClassifier()], 'preprocessing': [StandardScaler(), None],\n",
    "    #  'classifier__n_neighbors': [1,3,5]\n",
    "    # },\n",
    "    # {'classifier': [LinearRegression()], 'preprocessing': [StandardScaler(), None]\n",
    "    # },\n",
    "    # {'classifier': [DecisionTreeClassifier()], 'preprocessing': [StandardScaler(), None],\n",
    "    #  'classifier__max_depth': [1,2,3,4]\n",
    "    # },\n",
    "    {'classifier': [RandomForestClassifier()],\n",
    "     'preprocessing': [StandardScaler(),None],\n",
    "     'classifier__max_features': [1, int(sqrt(len(features_to_use))), len(features_to_use)],\n",
    "     'classifier__n_estimators': [1, 10, 100],\n",
    "     'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    {'classifier': [RandomForestClassifier()],\n",
    "     'preprocessing': [None],\n",
    "     'classifier__max_features': [len(features_to_use)],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__min_samples_split': [10]\n",
    "    }\n",
    "    ]\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', RandomForestClassifier())], memory=\"cache_folder\")\n",
    "grid_search = GridSearchCV(pipe,param_grid,cv=5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "grid_search.fit(X_train[features_to_use].astype(float),y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid_search.score(X_test[features_to_use].astype(float), y_test)))\n",
    "\n",
    "chosen_model = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy = X_test\n",
    "X_test_copy[\"prediction\"] = chosen_model.predict(X_test[features_to_use].astype(float))\n",
    "X_test_copy[\"truth\"] = y_test\n",
    "test_errors = X_test_copy[~(X_test_copy[\"prediction\"]==X_test_copy[\"truth\"])]\n",
    "display(test_errors[[\"artist_name\",\"name\",\"prediction\",\"truth\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope,client_id=client_id,client_secret=client_secret,redirect_uri=redirect_uri))\n",
    "prediction_tracks = get_all_playlist_track_details(sp,prediction_playlist_id)\n",
    "prediction_tracks_df = dict_list_to_dataframe(prediction_tracks)\n",
    "prediction_tracks_df[\"prediction: is metal?\"] = chosen_model.predict(prediction_tracks_df[features_to_use])\n",
    "prediction_tracks_df[\"probability\"] = chosen_model.predict_proba(prediction_tracks_df[features_to_use])[:,1]\n",
    "display(prediction_tracks_df[[\"artist_name\",\"name\",\"prediction: is metal?\",\"probability\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6738ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(data,model):\n",
    "    n_features = data.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), features_to_use)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(X,dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "from sklearn.tree import export_graphviz\n",
    "graph_file = os.path.join(root_location,\"tree.dot\")\n",
    "export_graphviz(dtree, out_file=graph_file, class_names=[\"Metallica\", \"Madonna\"],\n",
    "                feature_names=features_to_use, impurity=False, filled=True)\n",
    "import graphviz\n",
    "with open(graph_file) as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee957d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

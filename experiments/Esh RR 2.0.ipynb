{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import spotify_utils as spu\n",
    "from os.path import join as pj\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "REFRESH_CACHE = False\n",
    "seen_playlist_id = \"5al4jEBoq01LPmFDuGDnq4\"      # Automated: Reviewed Items\n",
    "played_playlist_id = \"7EHT9D4ygqDlyGfqcFvkUv\"    # 5 Esh Played\n",
    "inbox_playlist_id = \"1xsuqA0HU4bSosdaPyVlWG\"     # 1 Esh Review\n",
    "features_to_use = [\"duration\",\"previous_artist_plays\"] + spu.audio_features_to_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_CACHE:\n",
    "    sp = spu.spotify_connect()\n",
    "    seen_tracks = spu.get_playlist_tracks(sp,seen_playlist_id,audio_features=True)\n",
    "    played_tracks = spu.get_playlist_tracks(sp,played_playlist_id)\n",
    "    review_tracks = spu.get_playlist_tracks(sp,inbox_playlist_id,audio_features=True)\n",
    "    seen_tracks.to_csv('seen_tracks.csv',index=False)\n",
    "    played_tracks.to_csv('played_tracks.csv',index=False)\n",
    "    review_tracks.to_csv('review_tracks.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tracks = pd.read_csv('seen_tracks.csv')\n",
    "played_tracks = pd.read_csv('played_tracks.csv')[\"id\"]\n",
    "seen_tracks = seen_tracks.merge(played_tracks,how='left',on=[\"id\"],indicator=\"played\")\n",
    "seen_tracks[\"played\"] = seen_tracks[\"played\"].apply(lambda i: 1 if i==\"both\" else 0)\n",
    "seen_tracks = seen_tracks.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "# No need to import duckdb_engine\n",
    "#  SQLAlchemy will auto-detect the driver needed based on your connection string!\n",
    "\n",
    "# Import ipython-sql Jupyter extension to create SQL cells\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n",
    "%sql SELECT 'Off and flying!' as a_duckdb_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql t0 << select * from seen_tracks\n",
    "%sql select count(*) from t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql t1 << \n",
    "select * \n",
    "from (\n",
    "    select *,row_number() over (partition by artist_id,track_name order by playlist_offset) as duplicate_index\n",
    "    from t0\n",
    ")\n",
    "where duplicate_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[\"played\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql t2 <<\n",
    "select * from (\n",
    "    select *,\n",
    "    sum(played) over (partition by artist_id) as total_artist_plays\n",
    "    from t1\n",
    ")\n",
    "where total_artist_plays < 2 or played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2[\"played\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql t3 <<\n",
    "select *,coalesce(sum(played) over (\n",
    "    partition by artist_id\n",
    "    order by playlist_offset\n",
    "    rows between unbounded preceding and 1 preceding \n",
    "    ),0) as previous_artist_plays\n",
    "from t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb214ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3[\"previous_artist_plays\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff78638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t3[features_to_use]\n",
    "y = t3[\"played\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b662cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def discrete_scatter(x1, x2, y=None, markers=None, s=10, ax=None,\n",
    "                     labels=None, padding=.2, alpha=1, c=None, markeredgewidth=None):\n",
    "    \"\"\"Adaption of matplotlib.pyplot.scatter to plot classes or clusters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1 : nd-array\n",
    "        input data, first axis\n",
    "    x2 : nd-array\n",
    "        input data, second axis\n",
    "    y : nd-array\n",
    "        input data, discrete labels\n",
    "    cmap : colormap\n",
    "        Colormap to use.\n",
    "    markers : list of string\n",
    "        List of markers to use, or None (which defaults to 'o').\n",
    "    s : int or float\n",
    "        Size of the marker\n",
    "    padding : float\n",
    "        Fraction of the dataset range to use for padding the axes.\n",
    "    alpha : float\n",
    "        Alpha value for all points.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if y is None:\n",
    "        y = np.zeros(len(x1))\n",
    "\n",
    "    unique_y = np.unique(y)\n",
    "\n",
    "    if markers is None:\n",
    "        markers = ['o', '^', 'v', 'D', 's', '*', 'p', 'h', 'H', '8', '<', '>'] * 10\n",
    "\n",
    "    if len(markers) == 1:\n",
    "        markers = markers * len(unique_y)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = unique_y\n",
    "\n",
    "    # lines in the matplotlib sense, not actual lines\n",
    "    lines = []\n",
    "\n",
    "    current_cycler = mpl.rcParams['axes.prop_cycle']\n",
    "\n",
    "    for i, (yy, cycle) in enumerate(zip(unique_y, current_cycler())):\n",
    "        mask = y == yy\n",
    "        # if c is none, use color cycle\n",
    "        if c is None:\n",
    "            color = cycle['color']\n",
    "        elif len(c) > 1:\n",
    "            color = c[i]\n",
    "        else:\n",
    "            color = c\n",
    "        # use light edge for dark markers\n",
    "        if np.mean(colorConverter.to_rgb(color)) < .4:\n",
    "            markeredgecolor = \"grey\"\n",
    "        else:\n",
    "            markeredgecolor = \"black\"\n",
    "\n",
    "        lines.append(ax.plot(x1[mask], x2[mask], markers[i], markersize=s,\n",
    "                             label=labels[i], alpha=alpha, c=color,\n",
    "                             markeredgewidth=markeredgewidth,\n",
    "                             markeredgecolor=markeredgecolor)[0])\n",
    "\n",
    "    if padding != 0:\n",
    "        pad1 = x1.std() * padding\n",
    "        pad2 = x2.std() * padding\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_xlim(min(x1.min() - pad1, xlim[0]), max(x1.max() + pad1, xlim[1]))\n",
    "        ax.set_ylim(min(x2.min() - pad2, ylim[0]), max(x2.max() + pad2, ylim[1]))\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap, colorConverter, LinearSegmentedColormap\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# keep the first two principal components of the data\n",
    "pca = PCA(n_components=2,random_state=0)\n",
    "# fit PCA model to breast cancer data\n",
    "pca.fit(X)\n",
    "\n",
    "# transform data onto the first two principal components\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(\"Original shape: {}\".format(str(X_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "\n",
    "# plot first vs. second principal component, colored by class\n",
    "plt.figure(figsize=(8, 8))\n",
    "discrete_scatter(X_pca[:, 0], X_pca[:, 1], y)\n",
    "plt.legend(features_to_use, loc=\"best\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef75ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846cb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours,CondensedNearestNeighbour,NeighbourhoodCleaningRule\n",
    "\n",
    "print(pd.DataFrame(y).value_counts())\n",
    "enn = NeighbourhoodCleaningRule(kind_sel=\"mode\",n_neighbors=50)\n",
    "X_pca_enn,y_enn = enn.fit_resample(X_pca,y)\n",
    "print(pd.DataFrame(y_enn).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99769756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot first vs. second principal component, colored by class\n",
    "plt.figure(figsize=(8, 8))\n",
    "discrete_scatter(X_pca_enn[:, 0], X_pca_enn[:, 1], y_enn)\n",
    "plt.legend(features_to_use, loc=\"best\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# build the clustering model\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_pca)\n",
    "\n",
    "discrete_scatter(X_pca[:, 0], X_pca[:, 1], kmeans.labels_, markers='o')\n",
    "discrete_scatter(\n",
    "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1],\n",
    "    markers='^', markeredgewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=2)\n",
    "assignment = agg.fit_predict(X)\n",
    "\n",
    "discrete_scatter(X_pca[:, 0], X_pca[:, 1], assignment)\n",
    "plt.legend([\"Cluster 0\", \"Cluster 1\"], loc=\"best\")\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        \"classifier\": [DecisionTreeClassifier(),RandomForestClassifier()],\n",
    "        'undersampler': [EditedNearestNeighbours(),NeighbourhoodCleaningRule(kind_sel=\"mode\")],\n",
    "        \"undersampler__n_neighbors\": [1,5,50,100,500]\n",
    "\n",
    "    }\n",
    "    #{'classifier': [RandomForestClassifier(random_state=0)],\n",
    "     #'classifier__max_features': [1, int(sqrt(len(features_to_use))), len(features_to_use)],\n",
    "     #'classifier__n_estimators': [1, 10, 100],\n",
    "     #'classifier__min_samples_split': [2, 5, 10]\n",
    "     #'oversampler': [RandomOverSampler(random_state=0),SMOTE()],\n",
    "     #'oversampler__sampling_strategy': [0.1,0.3,0.5],\n",
    "     #'undersampler': [RandomUnderSampler(random_state=0)],\n",
    "     #'undersampler__sampling_strategy': [0.5,0.7,0.9]\n",
    "    #},\n",
    "    #{#'classifier': [RandomForestClassifier(random_state=0)],\n",
    "    # #'classifier__max_features': [1, int(sqrt(len(features_to_use))), len(features_to_use)],\n",
    "    # #'classifier__n_estimators': [1, 10, 100],\n",
    "    # #'classifier__min_samples_split': [2, 5, 10],\n",
    "    # 'oversampler':[RandomOverSampler(random_state=0),SMOTE()],\n",
    "    # 'oversampler__sampling_strategy': [0.1,0.3,0.5],\n",
    "    # 'undersampler': [TomekLinks(sampling_strategy=\"majority\")]\n",
    "    #}\n",
    "    ]\n",
    "#pipe = Pipeline([('classifier', RandomForestClassifier(random_state=0,n_estimators=10,max_features=10))], memory=\"cache_folder\")\n",
    "pipe = Pipeline([(\"undersampler\",RandomUnderSampler()),('classifier', LogisticRegression())], memory=\"cache_folder\")\n",
    "grid_search = GridSearchCV(pipe,param_grid,cv=5,scoring=\"f1_macro\",verbose=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca,y,stratify=y,test_size=0.25,random_state=0)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation f1_macro score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "chosen_model = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = chosen_model.predict(X_test)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='example estimator')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(data,model):\n",
    "    n_features = data.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), features_to_use)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(X,chosen_model.best_estimator_[\"classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tracks = pd.read_csv(\"review_tracks.csv\").dropna()\n",
    "played_tracks = pd.read_csv(\"played_tracks.csv\")\n",
    "%sql review_tracks2 << select *,(select count(*) from played_tracks pt where pt.artist_id=rt.artist_id) as previous_artist_plays from review_tracks rt\n",
    "X_pred = review_tracks2[features_to_use]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_pred_scaled = scaler.transform(X_pred)\n",
    "\n",
    "pca = PCA(n_components=2,random_state=0)\n",
    "pca.fit(X_pred_scaled)\n",
    "X_pred_scaled_pca = pca.transform(X_pred_scaled)\n",
    "\n",
    "\n",
    "y_predict_proba = pd.DataFrame(chosen_model.predict_proba(X_pred_scaled_pca),columns=[\"0_probability\",\"1_probability\"])\n",
    "review_tracks2[\"probability\"] = y_predict_proba[\"1_probability\"]\n",
    "res = review_tracks2.sort_values(\"probability\",ascending=False)\n",
    "res[\"uri\"].to_csv(\"review_ranked_output.csv\",index=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"probability\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_pca,columns=[\"a\",\"b\"])\n",
    "data[\"played\"] = y\n",
    "\n",
    "features_to_use_hist = [\"a\",\"b\"]\n",
    "\n",
    "fig, axes = plt.subplots(15, 2, figsize=(10, 20))\n",
    "unplayed = data[data.played == 0][features_to_use_hist]\n",
    "played = data[data.played == 1][features_to_use_hist]\n",
    "\n",
    "ax = axes.ravel()\n",
    "\n",
    "for i in range(len(features_to_use_hist)):\n",
    "    print(str(i))\n",
    "    _, bins = np.histogram(data[features_to_use_hist].iloc[:, i], bins=50)\n",
    "    ax[i].hist(unplayed.iloc[:, i], bins=bins, color=\"blue\", alpha=.5)\n",
    "    ax[i].hist(played.iloc[:, i], bins=bins, color=\"red\", alpha=.5)\n",
    "    ax[i].set_title(features_to_use_hist[i])\n",
    "    ax[i].set_yticks(())\n",
    "ax[0].set_xlabel(\"Feature magnitude\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].legend([\"unplayed\", \"played\"], loc=\"best\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b826e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esh-release-radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "660bfd33c16c2b715e68b58c766438cd9c0ad5e38540ef47195a2db6e6d2d1f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
